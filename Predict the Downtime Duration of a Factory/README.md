**Predicting the downtime duration of a factory**

**Problem Description:**

   IAn electric car manufacturing company, 'Kesla', with several factories is seeing exponential growth in demand due to the sudden increase of subsidies for EVs in the country.

	The car manufacturer, however, is not able to handle the demand and has tasked a team of DataScience consultants to identify potential areas to quickly increase the efficiency without operational changes.
	
	The team of Data Science consultants saw that without changing any of the data that is being collected, a predictive model can be built that predicts the downtime of a factory, thereby allowing the few engineers present in the engineering team to very quickly most important factories that would cause the most significant downtime.
	
	The Cheif Data Scientists have now curated a dataset, where we have several variables that it believes impact the `downtime_duration`. They have tracked three different downtime durations.
	
	The three classes of ` downtime_duration `

	0 - Low downtime (15 minutes to 1 hour)

	1 - Downtime that lasts anywhere between 1 hour and 24 hours

	2 - for long downtimes that can last from 24 hours to sometimes even several days
   
**About Data:**

There are 7 CSV files provided to us, they are described below:

● `train_data.csv`: It has a unique event `id` for each observation of the `outage_duration` in a particular `area_code`

● `test_data.csv`: Similar to the train dataset, we are provided with an `id` and an `area_code`, we are expected to predict the `outage_duration` for each of the records

● `broadband_data.csv`: For each of the event `id`s mentioned in the `train_data.csv` and `student_test.csv` files and also some additional `id`s there is a record of the `broadband_type` that is stored in the dataset. There are `10 different types` of broadbands that are observed in the dataset

● `outage_data.csv`: For each of the event `id`s mentioned in the `train_data.csv` and `student_test.csv` files and also some additional `id`s there is a record of the `outage_type` that is stored in the dataset. There are `5` different `outage_type`'s recorded in the dataset.

● `report_data.csv`: For each event `id` there are `log_report_type` and `volume` columns are recorded. `log_report_type` is a type of the recorded report generated by a technical team member after evaluating the outage. `volume` is the volume of data handled in the area at the time of report in custom company specific units.

● `server_data.csv`: For each of the event `id`s mentioned in the `train_data.csv` and `student_test.csv` files and also some additional `id`s there is a record of the `transit_server_type` that is stored in the dataset. Transit Servers handle the requests and responses of the customers.

● `sample_submission.csv`: The format of CSV file required for submission to the evaluation backend

The different `broadband_type`’s are given below:

			{
			broadband_type_8 : 'ADSL 1',
			broadband_type_2 : 'ADSL 2',
			broadband_type_6 : 'ADSL 2+',
			broadband_type_7 : 'Cable',
			broadband_type_4 : 'Fiber 1',
			broadband_type_9 : 'BPL',
			broadband_type_3 : 'Fiber 2',
			broadband_type_10 : 'Fiber High Speed',
			broadband_type_1 : 'Fiber Ultra',
			broadband_type_5 : 'Fiber Ultra Max'
			}

**Description of the columns present in the dataset.**

● `id` is the instance where the event was recorded when there was an outage in the broadband connectivity in an area 

● `area_code` is a categorical column, in which each unique value refers to an area where the `outage_duration` has been measured

● `broadband_type` is the technology that the ISP uses for delivering broadband internet connection, there can be multiple types of broadband connections in a single area 

● `outage_type` signifies the `5` different types of outages as classified by the engineering experts who remotely diagnose the issue, once reported 

● `log_report_type` column signifies one of the `386` different types of reports generated by customer service representatives who record issues and classify them as one of the 386 different types of issues 

● `transit_server_type` is the type of transit server that handles the traffic of data and route the incoming and outgoing web traffic 

● `volume` is the recorded data, in masked units, for 10 minutes prior to the time of recording the observation as per custom company specific units.

**Evaluation Metric:**

The evaluation metric used for this hackathon would be the **F1 Macro Average**
